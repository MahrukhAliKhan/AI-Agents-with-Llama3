{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 01: Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYyEre0icWpp",
    "outputId": "5634bb91-b352-4a5d-ad86-24c103b009c6"
   },
   "outputs": [],
   "source": [
    "%pip install 'crewai[tools]'==0.28.8      \n",
    "%pip install langchain-groq==0.1.3        \n",
    "%pip install duckduckgo-search==5.3.0 \n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 02: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahrukh/NLP/agents-with-llama-3/venv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:898: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `CrewAgentExecutor` to V2.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os                                         #for interacting with operating system(file paths, env-variables)\n",
    "import re                                         #for working with regular expressions(text pattern matching)                                     \n",
    "from datetime import datetime                     #for date and time\n",
    "\n",
    "import pandas as pd                               #for data handling\n",
    "import requests                                   #for web requests\n",
    "from crewai import Agent, Crew, Process, Task     #framework to build autonomous AI Agents\n",
    "from crewai_tools import tool\n",
    "from langchain.agents import load_tools           #LangChain is a framework used to build applications powered by large language models (LLMs)\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function: to process a string containing multiple comma-separated entries enclosed in square brackets and return a cleaned list of those entries.\n",
    "def format_response(response:str ) -> str:\n",
    "    entries = re.split(r\"(?<=]),(?=\\[])\", response)\n",
    "    return [entry.strip(\"[]\") for entry in entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"<YOUR_GROQ_API_KEY_HERE>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 03: Initializes a DuckDuckGo Search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchResults(backend=\"news\", num_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = search_tool.run(\"Earthquake\")\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = search_tool.run(\"Rainfall\")\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_tools = load_tools([\"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hrufH75dpvLc"
   },
   "outputs": [],
   "source": [
    "human_tools = load_tools([\"human\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 04: Create Dataframe of Fetched Earthquake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch recent earthquake data:\n",
    "def get_recent_eathquake_data() -> pd.DataFrame:\n",
    "    url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.geojson\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    features = data[\"features\"]\n",
    "\n",
    "    records = [\n",
    "        {\n",
    "            \"place\": feature[\"properties\"][\"place\"],\n",
    "            \"magnitude\": feature[\"properties\"][\"mag\"],\n",
    "            \"time\": datetime.utcfromtimestamp(feature[\"properties\"][\"time\"] / 1000),\n",
    "            \"url\": feature[\"properties\"][\"url\"]\n",
    "        } for feature in features\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Correctly cut the magnitudes into severity categories\n",
    "    df[\"severity\"] = pd.cut(\n",
    "        df[\"magnitude\"],\n",
    "        bins=[0, 2, 4, 6, 7.5, 10],\n",
    "        labels=[\"Very Minor\", \"Minor\", \"Moderate\", \"Strong\", \"Major\"]\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14 km SE of Anza, CA</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2025-04-17 08:41:41.330</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>Very Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 km NW of The Geysers, CA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2025-04-17 08:37:02.240</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>Very Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 km NW of Anza, CA</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2025-04-17 08:36:05.250</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>Very Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 km ESE of Alum Rock, CA</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2025-04-17 08:23:08.900</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>Very Minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40 km NW of Ninilchik, Alaska</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2025-04-17 08:09:48.107</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>Minor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           place  magnitude                    time  \\\n",
       "0           14 km SE of Anza, CA       0.84 2025-04-17 08:41:41.330   \n",
       "1     7 km NW of The Geysers, CA       0.75 2025-04-17 08:37:02.240   \n",
       "2           12 km NW of Anza, CA       0.79 2025-04-17 08:36:05.250   \n",
       "3      9 km ESE of Alum Rock, CA       1.56 2025-04-17 08:23:08.900   \n",
       "4  40 km NW of Ninilchik, Alaska       2.50 2025-04-17 08:09:48.107   \n",
       "\n",
       "                                                 url    severity  \n",
       "0  https://earthquake.usgs.gov/earthquakes/eventp...  Very Minor  \n",
       "1  https://earthquake.usgs.gov/earthquakes/eventp...  Very Minor  \n",
       "2  https://earthquake.usgs.gov/earthquakes/eventp...  Very Minor  \n",
       "3  https://earthquake.usgs.gov/earthquakes/eventp...  Very Minor  \n",
       "4  https://earthquake.usgs.gov/earthquakes/eventp...       Minor  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quake_df = get_recent_eathquake_data()\n",
    "quake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 05: Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 08:41:41 | 14 km SE of Anza, CA | Magnitude: 0.8 | Severity: Very Minor\n",
      "2025-04-17 08:37:02 | 7 km NW of The Geysers, CA | Magnitude: 0.8 | Severity: Very Minor\n",
      "2025-04-17 08:36:05 | 12 km NW of Anza, CA | Magnitude: 0.8 | Severity: Very Minor\n",
      "2025-04-17 08:23:08 | 9 km ESE of Alum Rock, CA | Magnitude: 1.6 | Severity: Very Minor\n",
      "2025-04-17 08:09:48 | 40 km NW of Ninilchik, Alaska | Magnitude: 2.5 | Severity: Minor\n",
      "2025-04-17 08:09:32 | 16 km N of Ocotillo Wells, CA | Magnitude: 1.0 | Severity: Very Minor\n",
      "2025-04-17 08:06:24 | 2 km E of The Geysers, CA | Magnitude: 0.9 | Severity: Very Minor\n",
      "2025-04-17 08:03:25 | 2 km WSW of Julian, CA | Magnitude: 0.7 | Severity: Very Minor\n",
      "2025-04-17 08:02:20 | 8 km NNW of The Geysers, CA | Magnitude: 0.6 | Severity: Very Minor\n",
      "2025-04-17 07:50:16 | 5 km NE of Loyalton, California | Magnitude: 1.5 | Severity: Very Minor\n",
      "2025-04-17 07:36:44 | 4 km SW of Indios, Puerto Rico | Magnitude: 2.2 | Severity: Minor\n",
      "2025-04-17 07:29:16 | 16 km WSW of Johannesburg, CA | Magnitude: 1.2 | Severity: Very Minor\n",
      "2025-04-17 07:26:41 | 21 km SW of Lospalos, Timor Leste | Magnitude: 4.9 | Severity: Moderate\n",
      "2025-04-17 07:26:25 | 11 km NW of The Geysers, CA | Magnitude: 0.4 | Severity: Very Minor\n",
      "2025-04-17 06:49:17 | 11 km NW of The Geysers, CA | Magnitude: 0.5 | Severity: Very Minor\n"
     ]
    }
   ],
   "source": [
    "#Format the first 10 Dataframe and prints multi-line string\n",
    "text_output = []\n",
    "for index, row in quake_df.head(15).iterrows():\n",
    "    text_output.append(f\"{row['time'].strftime('%Y-%m-%d %H:%M:%S')} | {row['place']} | Magnitude: {row['magnitude']:.1f} | Severity: {row['severity']}\") #fromats magnitude to 1 decimal place\n",
    "formatted_text=\"\\n\".join(text_output)\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Earthquake tool\n",
    "@tool(\"earthquake tool\")\n",
    "def recent_earthquake_tool() -> str:\n",
    "    \"\"\"Get recent earthquake data for the past day (top 60 events)\"\"\"\n",
    "    quake_df = get_recent_eathquake_data()\n",
    "    text_output = []\n",
    "    for index, row in quake_df.head(60).iterrows():\n",
    "        text_output.append(\n",
    "            f\"{row['time'].strftime('%Y-%m-%d %H:%M:%S')} | {row['place']} | Magnitude: {row['magnitude']:.1f} | Severity: {row['severity']}\"\n",
    "        )\n",
    "    return \"\\n\".join(text_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"search tool\")\n",
    "def earthquake_news_tool(location: str ) -> str:\n",
    "    \"\"\"Get recent news realted to earthquakes in a given location\"\"\"\n",
    "    return search_tool.run(location+\"earthquake news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 06: Using Llama-3 Model with Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\") #temperature controls how random AI's output will be -> temp=0 (makes it deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning is a powerful technique in deep learning that involves adjusting the pre-trained model's weights to fit a new task or dataset. There are several techniques to fine-tune a pre-trained model, and I'll outline some of the most popular ones:\n",
      "\n",
      "1. **Last Layer Fine-Tuning**: This involves freezing all the layers except the last layer (usually the classification layer) and updating only the last layer's weights to fit the new task. This technique is useful when the pre-trained model's features are general enough to be applicable to the new task.\n",
      "\n",
      "2. **Full Model Fine-Tuning**: In this technique, all the layers of the pre-trained model are updated during fine-tuning. This approach is useful when the new task requires significant changes to the model's features.\n",
      "\n",
      "3. **Freeze and Unfreeze**: This technique involves freezing certain layers of the pre-trained model and unfreezing others. The frozen layers are not updated during fine-tuning, while the unfrozen layers are updated. This approach is useful when some layers of the pre-trained model are general enough to be applicable to the new task, while others require updates.\n",
      "\n",
      "4. **Layer-wise Learning Rate**: In this technique, different learning rates are assigned to different layers of the pre-trained model. This approach is useful when some layers require more aggressive updates than others.\n",
      "\n",
      "5. **Gradient-based Fine-Tuning**: This technique involves using gradient-based optimization methods (e.g., SGD, Adam) to update the pre-trained model's weights. The gradients are computed with respect to the new task's loss function.\n",
      "\n",
      "6. **Knowledge Distillation**: This technique involves training a smaller model (the student) to mimic the behavior of a pre-trained model (the teacher). The student model is trained to predict the same outputs as the teacher model, and the knowledge is distilled from the teacher to the student.\n",
      "\n",
      "7. **Multi-Task Fine-Tuning**: In this technique, the pre-trained model is fine-tuned on multiple tasks simultaneously. This approach is useful when the tasks are related and share common features.\n",
      "\n",
      "8. **Online Fine-Tuning**: This technique involves fine-tuning the pre-trained model on a stream of data, where the model is updated incrementally as new data arrives.\n",
      "\n",
      "9. **Meta-Learning**: This technique involves training a model to adapt to new tasks quickly, by learning how to fine-tune itself on a few examples from the new task.\n",
      "\n",
      "10. **Transfer Learning with Domain Adaptation**: This technique involves fine-tuning a pre-trained model on a new dataset that has a different distribution than the original dataset. This approach is useful when the new dataset is small or has limited labeled data.\n",
      "\n",
      "These are some of the most popular fine-tuning techniques, and the choice of technique depends on the specific problem, dataset, and model architecture.\n",
      "CPU times: user 12.7 ms, sys: 0 ns, total: 12.7 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "system=\"You are an experienced Machine Learning & AI-Engineer.\"\n",
    "human= \"{text}\"\n",
    "prompt= ChatPromptTemplate.from_messages([(\"system\", system),(\"human\",human)])\n",
    "chain=prompt | llm    #pipe operator (|) to compose a prompt with a language model (LLM), effectively creating a processing chain.\n",
    "response = chain.invoke({\"text\":\"What are the difference techniques of Fine-Tuning?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LbEjEtzvyl5"
   },
   "source": [
    "## Step # 07: Initialize Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Senior Environmental Customer Communicator\n",
    "customer_communicator = Agent (\n",
    "    role=\"Senior environmental and natural events communicator\",\n",
    "    goal=\"Understand what natural events the customer is asking about, such as earthquake, rainfall, weather patterns, or environmental changes, and provide clear, accurate, and relevanr information\",\n",
    "    backstory=\"\"\"You're a highly experienced specialist in communicating about natural events including earthquakes, rainfall, weather, and environmental conditions. \n",
    "    You help users by answering their questions and providing helpful explanations, facts and insights on these topics.\"\"\",\n",
    "    verbose=True, \n",
    "    allow_delegation=False,     #handles things directly without delegating\n",
    "    llm=llm,\n",
    "    max_iter=5,\n",
    "    memory=True,                #whether this agent remembers context/history\n",
    "    tools=human_tools,          #tools available to this agent(search tools, APIs etc)\n",
    "    )\n",
    "\n",
    "#Enviornmental News Analyst Agent\n",
    "news_analyst = Agent(\n",
    "    role=\"Earthquake News Analyst\",\n",
    "    goal=\"\"\"Get recent earthquake news. Write 1 paragraph analysis of recent seismic activities \n",
    "    and classify the trend — increasing, decreasing, or stable.\"\"\",\n",
    "    backstory=\"\"\"You're an expert analyst of natural disaster trends based on earthquake news. \n",
    "    You have a thorough understanding of seismological patterns and global tectonic activities, \n",
    "    specializing in analyzing the news impact.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    "    max_iter=5,\n",
    "    memory=True,\n",
    "    tools=[earthquake_news_tool],\n",
    ")\n",
    "\n",
    "#Environmental Newsletter Writer\n",
    "writer = Agent (\n",
    "    role=\"Environmental Newsletter Writer\",\n",
    "    goal=\"\"\"Write an insightful, compelling, and informative 3-paragraph-long newsletter based on the latest environmental events and natural phenomena report.\"\"\",\n",
    "    backstory=\"\"\"You're deeply familiar with natural events, environmental science, and climate-related topics. \n",
    "    You understand complex concepts like earthquake science, rainfall patterns, climate trends, and their real-world impacts — and have a gift for transforming this technical information into engaging, clear, and easy-to-read articles for a general audience.\n",
    "\n",
    "    You're a master of communication, using narratives and structure to keep readers engaged.\n",
    "    Your writing focuses on clarity, conciseness, and a pleasant flow that makes technical content approachable.\n",
    "\n",
    "    Some of your writing techniques include:\n",
    "\n",
    "    - Start with a 3-bullet executive summary highlighting the most important points\n",
    "    - Use bullet points and subheadings to make content skimmable and easy to follow\n",
    "    - Use real-world examples and analogies to explain complex environmental ideas\n",
    "    - Craft compelling introductions and conclusions to make your writing memorable and actionable\n",
    "\n",
    "    Your writing style turns even the driest scientific data into engaging and interesting newsletters for readers of all backgrounds. \"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=True,    # can delegate tasks to other agents if needed\n",
    "    llm=llm,\n",
    "    max_iter=10,\n",
    "    memory=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 08: Initialize Tasks for Agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task for Senior Environmental Customer Communicator Agent\n",
    "get_natural_event_topics = Task (\n",
    "    description=f\"\"\"Ask the user which natural events or environmental topics they're interested in (like earthquake, rainfall, temperature trends, storms, or other climate events).\"\"\",\n",
    "    expected_output=\"\"\"Create a list of the natural events or environmental topics that the user wants information about.\n",
    "    Example: \n",
    "    events = 'earthquake, rainfall, storm'\n",
    "    \"\"\",\n",
    "    agent=customer_communicator,\n",
    ")\n",
    "\n",
    "#Task for Environmental Events Analyst Agent\n",
    "get_event_news_and_data = Task(\n",
    "    description = f\"\"\"Take the list of natural events and always include 'earthquake' and 'rainfall' to it(if not requested)\n",
    "    Use the search tool to gather news, updates, and scientific data for each topic individually. \n",
    "    The current date is {datetime.now()}.\n",
    "    Summarize the information into a clear, helpful report.\"\"\",\n",
    "    expected_output=\"\"\"A summary of the current environmental situation and a one-sentence summary for\n",
    "    each requested natural event or topic. Include a risk or impact score between 0 and 100 (0 being no risk/impact, 100 being severe risk/impact). Use this format:\n",
    "    <EVENT>\n",
    "    <SUMMARY BASED ON NEWS AND DATA>\n",
    "    <CURRENT TREND OR PATTERN>\n",
    "    <RISK/IMPACT SCORE>\n",
    "    \"\"\",\n",
    "    agent=news_analyst,\n",
    "    context=[get_natural_event_topics],\n",
    ")\n",
    "\n",
    "#Task for Environmental Newsletter Writer Agent\n",
    "write_environment_newsletter = Task(\n",
    "    description = f\"\"\"\n",
    "    Use the environmental events report to create a daily newsletter that highlights the most important points.\n",
    "    Focus on the event summaries, current trends, and risk/impact scores. Discuss near-term and future considerations.\n",
    "    The newsletter should be accessible to a wide audience and rely on clear, factual, and evidence-based information.\"\"\",\n",
    "    expected_output = \"\"\"An eloquent 3-paragraph newsletter formatted as markdown in an easy-to-read manner. It should contain: \n",
    "    - 3-bullet executive summary \n",
    "    - Introduction — set the overall context and hook the reader's interest\n",
    "    - Main section — detailed analysis including news summaries and risk/impact scores\n",
    "    - Summary — key facts and a future prediction: increasing, descreasing, or stable trend               \n",
    "    \"\"\",\n",
    "    agent=writer,\n",
    "    context=[get_event_news_and_data],    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step # 09: Initialize Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:16:15,477 - 137977149190144 - __init__.py-__init__:535 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents=[customer_communicator, news_analyst, writer],\n",
    "    tasks=[get_natural_event_topics,get_event_news_and_data, write_environment_newsletter],\n",
    "    verbose=0,   #Detailed logs\n",
    "    Process=Process.sequential, #how to coordinate these tasks\n",
    "    full_output=True,\n",
    "    share_crew=False,\n",
    "    manager_llm=llm,\n",
    "    max_iter=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=crew.kickoff()     #kickoff() -> method that triggers the execution"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
